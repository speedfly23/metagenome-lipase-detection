# Ø³Ø§Ø®Øª Ù¾ÙˆØ´Ù‡ scripts Ø§Ú¯Ù‡ Ù†ÛŒØ³Øª
mkdir -p scripts

# Ø§Ù†ØªÙ‚Ø§Ù„ prepare_data Ø¨Ù‡ scripts (Ø§Ú¯Ù‡ ØªÙˆ root Ù‡Ø³Øª)
mv prepare_data.py scripts/ 2>/dev/null || cp prepare_data.py scripts/

# Ø³Ø§Ø®Øª ÙØ§ÛŒÙ„ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
cat > scripts/train_model.py << 'EOF'
#!/usr/bin/env python3
"""
Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ ØªØ´Ø®ÛŒØµ Ù„ÛŒÙ¾Ø§Ø² Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ù…ØªØ§Ú˜Ù†ÙˆÙ…
Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡: speedfly23
"""
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from Bio import SeqIO
import joblib
import os
import argparse
from datetime import datetime

def train_and_predict(dataset_file, metagenome_file=None, threshold=0.7, n_jobs=12):
    """Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ"""
    
    print("ðŸ¤– Metagenome Lipase Detection - Model Training")
    print("ðŸ‘¤ speedfly23 - https://github.com/speedfly23/metagenome-lipase-detection")
    print(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("")
    
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„ dataset
    if not os.path.exists(dataset_file):
        print(f"âŒ ÙØ§ÛŒÙ„ dataset Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: {dataset_file}")
        print("ðŸ”„ Ø§Ø¨ØªØ¯Ø§ scripts/prepare_data.py Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯")
        return False
    
    print("ðŸ”„ Ù„ÙˆØ¯ dataset...")
    df = pd.read_csv(dataset_file)
    print(f"ðŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯: {len(df)}")
    print(f"ðŸ“Š ØªÙˆØ²ÛŒØ¹: {sum(df['label'])} Ù…Ø«Ø¨Øª ({sum(df['label'])/len(df)*100:.1f}%), {len(df) - sum(df['label'])} Ù…Ù†ÙÛŒ ({(len(df) - sum(df['label']))/len(df)*100:.1f}%)")
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ (3-mer)
    print("ðŸ§¬ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (3-mer)...")
    vectorizer = CountVectorizer(
        analyzer='char', 
        ngram_range=(3,3), 
        max_features=5000  # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² memory issue
    )
    X = vectorizer.fit_transform(df['sequence'])
    y = df['label']
    
    print(f"ðŸ“ Ø§Ø¨Ø¹Ø§Ø¯ Ù…Ø§ØªØ±ÛŒØ³ ÙˆÛŒÚ˜Ú¯ÛŒ: {X.shape}")
    
    # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
    print("ðŸ¤– Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Random Forest...")
    model = RandomForestClassifier(
        n_estimators=100, 
        random_state=42, 
        n_jobs=n_jobs,
        max_depth=15,  # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¹Ù…Ù‚
        min_samples_split=5,
        min_samples_leaf=2
    )
    model.fit(X_train, y_train)
    
    # ØªØ³Øª Ø¯Ù‚Øª
    predictions = model.predict(X_test)
    probabilities = model.predict_proba(X_test)[:, 1]
    
    accuracy = accuracy_score(y_test, predictions)
    print(f"âœ… Ø¯Ù‚Øª Ù…Ø¯Ù„: {accuracy:.4f}")
    
    # Ú¯Ø²Ø§Ø±Ø´ ØªÙØµÛŒÙ„ÛŒ
    print("\nðŸ“‹ Ú¯Ø²Ø§Ø±Ø´ Ú©Ù„Ø§Ø³ÛŒÙÛŒÚ©ÛŒØ´Ù†:")
    print(classification_report(y_test, predictions, target_names=['Non-Lipase', 'Lipase']))
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ùˆ vectorizer
    joblib.dump(model, "trained_model.pkl")
    joblib.dump(vectorizer, "vectorizer.pkl")
    print("ðŸ’¾ Ù…Ø¯Ù„ Ùˆ vectorizer Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯")
    
    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ù…ØªØ§Ú˜Ù†ÙˆÙ… (Ø§Ú¯Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù‡)
    if metagenome_file and os.path.exists(metagenome_file):
        print(f"ðŸ” Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØªØ§Ú˜Ù†ÙˆÙ…: {metagenome_file}")
        
        metagenome_sequences = []
        for record in SeqIO.parse(metagenome_file, "fasta"):
            if len(str(record.seq)) > 50:  # ÙÙ‚Ø· ØªÙˆØ§Ù„ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ù„Ù†Ø¯ØªØ± Ø§Ø² 50
                metagenome_sequences.append({
                    "id": record.id, 
                    "sequence": str(record.seq),
                    "length": len(str(record.seq))
                })
        
        if len(metagenome_sequences) == 0:
            print("âš ï¸  Ù‡ÛŒÚ† ØªÙˆØ§Ù„ÛŒ Ù…Ù†Ø§Ø³Ø¨ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ Ù…ØªØ§Ú˜Ù†ÙˆÙ… Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
            return True
            
        df_meta = pd.DataFrame(metagenome_sequences)
        print(f"ðŸ§¬ ØªØ¹Ø¯Ø§Ø¯ ORFâ€ŒÙ‡Ø§: {len(df_meta)}")
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        X_meta = vectorizer.transform(df_meta['sequence'])
        probabilities = model.predict_proba(X_meta)[:, 1]
        
        # ÙÛŒÙ„ØªØ± Ú©Ø§Ù†Ø¯ÛŒØ¯Ø§Ù‡Ø§ Ø¨Ø§ threshold Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        thresholds = [0.5, 0.7, 0.8, 0.9]
        
        for thresh in thresholds:
            candidates = df_meta[probabilities > thresh].copy()
            candidates['probability'] = probabilities[probabilities > thresh]
            candidates = candidates.sort_values('probability', ascending=False)
            
            print(f"\nðŸŽ¯ Ú©Ø§Ù†Ø¯ÛŒØ¯Ø§Ù‡Ø§ Ø¨Ø§ threshold > {thresh}: {len(candidates)}")
            
            if len(candidates) > 0:
                # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
                output_file = f"predicted_lipases_t{thresh}.csv"
                candidates.to_csv(output_file, index=False)
                
                print(f"ðŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {output_file}")
                print("ðŸ† Ø¨Ù‡ØªØ±ÛŒÙ† Ú©Ø§Ù†Ø¯ÛŒØ¯Ø§Ù‡Ø§:")
                for i, (_, row) in enumerate(candidates.head(5).iterrows()):
                    print(f"  {i+1}. {row['id']}: {row['probability']:.4f} (Ø·ÙˆÙ„: {row['length']} aa)")
        
        # Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ
        main_candidates = df_meta[probabilities > threshold].copy()
        if len(main_